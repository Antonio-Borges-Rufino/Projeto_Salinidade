{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tunningLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRF_-fOSVQE6"
      },
      "source": [
        "#1. Tunning de parametros para rede LSTM\n",
        "##2. especificações do tunning\n",
        "\n",
        "Camadas ocultas|Neuronios|Taxa de aprendizagem|Função de aprendizagem| Epocas\n",
        "---------------|---------|--------------------|---------|---------|\n",
        "        1      |  10-x+5-100   | 0.001 - 0.01       |Relu| 10-x+10- 100      \n",
        "  \n",
        "        \n",
        "##3. importar as bibliotecas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m261eM9_Vpri"
      },
      "source": [
        "###3.1 instalar a biblioteca do keras prórpia para o tunning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1SsDpXj7NTh"
      },
      "source": [
        "pip install -q -U keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S4bmiOOVuUA"
      },
      "source": [
        "###3.2 importar todas as bibliotecas que serão usadas no processo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2T-gFxa6165"
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras_tuner as kt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDg3aUd0V0UF"
      },
      "source": [
        "##4. Importar os dataset e deixar o dataset na estrutura de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlhijEbf7MB4"
      },
      "source": [
        "df_teste = pd.read_parquet('/content/drive/MyDrive/df_teste_norm')\n",
        "df_treino = pd.read_parquet('/content/drive/MyDrive/df_treino_norm')\n",
        "df_treino = df_treino.dropna()\n",
        "df_teste = df_teste.dropna()\n",
        "df_treino2 = df_treino[['TEMP_NORM','BATIMETRIA_NORM']]\n",
        "df_teste2 = df_teste[['TEMP_NORM','BATIMETRIA_NORM']]\n",
        "lista = list()\n",
        "for x,i in df_treino2.values:\n",
        "  lista.append([x,i])\n",
        "sal_treino = np.array(df_treino.SALINIDADE)\n",
        "pr_treino = np.array(lista)\n",
        "lista = list()\n",
        "for x,i in df_teste2.values:\n",
        "  lista.append([x,i])\n",
        "sal_teste = np.array(df_teste.SALINIDADE)\n",
        "pr_teste = np.array(lista)\n",
        "pr_teste = pr_teste.reshape(pr_teste.shape[0],pr_teste.shape[1],1)\n",
        "pr_treino = pr_treino.reshape(pr_treino.shape[0],pr_treino.shape[1],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoYbAtcCWTg0"
      },
      "source": [
        "## 5. Fazer o tunning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kuz4QZlH7UaD",
        "outputId": "233f5754-6f80-4f1a-bae2-ef180d46779f"
      },
      "source": [
        "def KerasTunnerLSTM1(hp):\n",
        "  input = tf.keras.layers.Input(shape=(2,1), name='Bat_Temp')\n",
        "  hiper_param = hp.Int('units', min_value=10, max_value=100, step=5)\n",
        "  lstm = tf.keras.layers.LSTM(units=hiper_param,activation='relu')(input)\n",
        "  output = tf.keras.layers.Dense(1,name='salinidade')(lstm)\n",
        "  modelo = tf.keras.Model(inputs=input, outputs=output)\n",
        "  taxa_apren =  hp.Choice('learning_rate', values=[0.001,0.002,0.003,0.004,0.005,0.006,0.007,0.008,0.009,0.01])\n",
        "  adan = tf.keras.optimizers.Adam(learning_rate=taxa_apren)\n",
        "  modelo.compile(optimizer=adan, loss='mse', metrics=['mae','mse'])\n",
        "  return modelo\n",
        "\n",
        "tuner = kt.Hyperband(KerasTunnerLSTM1,\n",
        "                     objective='val_mae',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory='my_dir2',\n",
        "                     project_name='salinidade')\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
        "tuner.search(pr_teste, sal_teste,epochs=10,batch_size=120,validation_split=0.2, callbacks=[stop_early])\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 04m 22s]\n",
            "val_mae: 0.8743407130241394\n",
            "\n",
            "Best val_mae So Far: 0.8601447939872742\n",
            "Total elapsed time: 00h 43m 55s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dQye4PWXWYWl"
      },
      "source": [
        "###5.1 Resultado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM-WYJEvIgfw",
        "outputId": "359676d0-39eb-4846-9b09-fe3f72ce04dc"
      },
      "source": [
        "best_hps.values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.007,\n",
              " 'tuner/bracket': 0,\n",
              " 'tuner/epochs': 10,\n",
              " 'tuner/initial_epoch': 0,\n",
              " 'tuner/round': 0,\n",
              " 'units': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKUuXZXJWcjP"
      },
      "source": [
        "##6. Melhor época para os dados de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dal2K1eUWyIF"
      },
      "source": [
        "###6.1 criar função"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8VHrhoyW08P"
      },
      "source": [
        "def KerasTunnerLSTM():\n",
        "  input = tf.keras.layers.Input(shape=(2,1), name='Bat_Temp')\n",
        "  lstm = tf.keras.layers.LSTM(units=30,activation='relu')(input)\n",
        "  output = tf.keras.layers.Dense(1,name='salinidade')(lstm)\n",
        "  modelo = tf.keras.Model(inputs=input, outputs=output)\n",
        "  adan = tf.keras.optimizers.Adam(learning_rate=0.007)\n",
        "  modelo.compile(optimizer=adan, loss='mse', metrics=['mae','mse'])\n",
        "  return modelo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOnR6Y2dXBiy"
      },
      "source": [
        "###6.2 treinar o modelo com os dados de teste para a melhor epoca"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDv1cLHAWh1-",
        "outputId": "20ac4428-43b5-44f9-ed27-bb28de2e4d31"
      },
      "source": [
        "modelo  = KerasTunnerLSTM()\n",
        "best_epoch = modelo.fit(pr_treino,sal_treino,epochs=100,batch_size=120)\n",
        "val_acc_per_epoch = best_epoch.history['mae']\n",
        "best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch))+1\n",
        "modelo.fit(pr_treino,sal_treino,epochs=best_epoch,batch_size=120)\n",
        "modelo.evaluate(pr_teste,sal_teste)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 10.9505 - mae: 1.2032 - mse: 10.9505\n",
            "Epoch 2/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.5247 - mae: 0.9548 - mse: 4.5247\n",
            "Epoch 3/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.4456 - mae: 0.9384 - mse: 4.4456\n",
            "Epoch 4/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.4166 - mae: 0.9295 - mse: 4.4166\n",
            "Epoch 5/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.3964 - mae: 0.9222 - mse: 4.3964\n",
            "Epoch 6/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.3889 - mae: 0.9197 - mse: 4.3889\n",
            "Epoch 7/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.3801 - mae: 0.9164 - mse: 4.3801\n",
            "Epoch 8/100\n",
            "10093/10093 [==============================] - 35s 4ms/step - loss: 4.3693 - mae: 0.9116 - mse: 4.3693\n",
            "Epoch 9/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.3638 - mae: 0.9099 - mse: 4.3638\n",
            "Epoch 10/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.3570 - mae: 0.9070 - mse: 4.3570\n",
            "Epoch 11/100\n",
            "10093/10093 [==============================] - 35s 4ms/step - loss: 4.3510 - mae: 0.9061 - mse: 4.3510\n",
            "Epoch 12/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.3403 - mae: 0.9047 - mse: 4.3403\n",
            "Epoch 13/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.3311 - mae: 0.9021 - mse: 4.3311\n",
            "Epoch 14/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.3159 - mae: 0.8967 - mse: 4.3159\n",
            "Epoch 15/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2900 - mae: 0.8868 - mse: 4.2900\n",
            "Epoch 16/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2643 - mae: 0.8792 - mse: 4.2643\n",
            "Epoch 17/100\n",
            "10093/10093 [==============================] - 35s 4ms/step - loss: 4.2545 - mae: 0.8776 - mse: 4.2545\n",
            "Epoch 18/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2507 - mae: 0.8766 - mse: 4.2507\n",
            "Epoch 19/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2458 - mae: 0.8753 - mse: 4.2458\n",
            "Epoch 20/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2434 - mae: 0.8755 - mse: 4.2434\n",
            "Epoch 21/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2401 - mae: 0.8737 - mse: 4.2401\n",
            "Epoch 22/100\n",
            "10093/10093 [==============================] - 34s 3ms/step - loss: 4.2390 - mae: 0.8744 - mse: 4.2390\n",
            "Epoch 23/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2378 - mae: 0.8730 - mse: 4.2378\n",
            "Epoch 24/100\n",
            "10093/10093 [==============================] - 35s 3ms/step - loss: 4.2352 - mae: 0.8732 - mse: 4.2352\n",
            "Epoch 25/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2324 - mae: 0.8718 - mse: 4.2324\n",
            "Epoch 26/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2300 - mae: 0.8723 - mse: 4.2300\n",
            "Epoch 27/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2271 - mae: 0.8712 - mse: 4.2271\n",
            "Epoch 28/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2263 - mae: 0.8714 - mse: 4.2263\n",
            "Epoch 29/100\n",
            "10093/10093 [==============================] - 35s 4ms/step - loss: 4.2254 - mae: 0.8712 - mse: 4.2254\n",
            "Epoch 30/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2258 - mae: 0.8718 - mse: 4.2258\n",
            "Epoch 31/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2260 - mae: 0.8721 - mse: 4.2260\n",
            "Epoch 32/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2236 - mae: 0.8712 - mse: 4.2236\n",
            "Epoch 33/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2224 - mae: 0.8704 - mse: 4.2224\n",
            "Epoch 34/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2238 - mae: 0.8711 - mse: 4.2238\n",
            "Epoch 35/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2194 - mae: 0.8707 - mse: 4.2194\n",
            "Epoch 36/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2206 - mae: 0.8701 - mse: 4.2206\n",
            "Epoch 37/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2180 - mae: 0.8693 - mse: 4.2180\n",
            "Epoch 38/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2184 - mae: 0.8703 - mse: 4.2184\n",
            "Epoch 39/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2186 - mae: 0.8700 - mse: 4.2186\n",
            "Epoch 40/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2172 - mae: 0.8688 - mse: 4.2172\n",
            "Epoch 41/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2157 - mae: 0.8691 - mse: 4.2157\n",
            "Epoch 42/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2148 - mae: 0.8684 - mse: 4.2148\n",
            "Epoch 43/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2134 - mae: 0.8678 - mse: 4.2134\n",
            "Epoch 44/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2124 - mae: 0.8677 - mse: 4.2124\n",
            "Epoch 45/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2132 - mae: 0.8675 - mse: 4.2132\n",
            "Epoch 46/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2129 - mae: 0.8679 - mse: 4.2129\n",
            "Epoch 47/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2112 - mae: 0.8668 - mse: 4.2112\n",
            "Epoch 48/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2117 - mae: 0.8674 - mse: 4.2117\n",
            "Epoch 49/100\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.2105 - mae: 0.8661 - mse: 4.2105\n",
            "Epoch 50/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2121 - mae: 0.8669 - mse: 4.2121\n",
            "Epoch 51/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2103 - mae: 0.8665 - mse: 4.2103\n",
            "Epoch 52/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2095 - mae: 0.8661 - mse: 4.2095\n",
            "Epoch 53/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2094 - mae: 0.8663 - mse: 4.2094\n",
            "Epoch 54/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2067 - mae: 0.8657 - mse: 4.2067\n",
            "Epoch 55/100\n",
            "10093/10093 [==============================] - 36s 4ms/step - loss: 4.2073 - mae: 0.8660 - mse: 4.2073\n",
            "Epoch 56/100\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.2067 - mae: 0.8660 - mse: 4.2067\n",
            "Epoch 57/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2071 - mae: 0.8654 - mse: 4.2071\n",
            "Epoch 58/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2073 - mae: 0.8657 - mse: 4.2073\n",
            "Epoch 59/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2061 - mae: 0.8655 - mse: 4.2061\n",
            "Epoch 60/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2047 - mae: 0.8651 - mse: 4.2047\n",
            "Epoch 61/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2060 - mae: 0.8661 - mse: 4.2060\n",
            "Epoch 62/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2041 - mae: 0.8648 - mse: 4.2041\n",
            "Epoch 63/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2046 - mae: 0.8653 - mse: 4.2046\n",
            "Epoch 64/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2056 - mae: 0.8652 - mse: 4.2056\n",
            "Epoch 65/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2048 - mae: 0.8650 - mse: 4.2048\n",
            "Epoch 66/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2025 - mae: 0.8643 - mse: 4.2025\n",
            "Epoch 67/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2027 - mae: 0.8644 - mse: 4.2027\n",
            "Epoch 68/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2021 - mae: 0.8638 - mse: 4.2021\n",
            "Epoch 69/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2028 - mae: 0.8648 - mse: 4.2028\n",
            "Epoch 70/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2013 - mae: 0.8637 - mse: 4.2013\n",
            "Epoch 71/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2032 - mae: 0.8641 - mse: 4.2032\n",
            "Epoch 72/100\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.2032 - mae: 0.8653 - mse: 4.2032\n",
            "Epoch 73/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2015 - mae: 0.8641 - mse: 4.2015\n",
            "Epoch 74/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2022 - mae: 0.8644 - mse: 4.2022\n",
            "Epoch 75/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2019 - mae: 0.8641 - mse: 4.2019\n",
            "Epoch 76/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2015 - mae: 0.8641 - mse: 4.2015\n",
            "Epoch 77/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2008 - mae: 0.8639 - mse: 4.2008\n",
            "Epoch 78/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2026 - mae: 0.8649 - mse: 4.2026\n",
            "Epoch 79/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2006 - mae: 0.8638 - mse: 4.2006\n",
            "Epoch 80/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2017 - mae: 0.8642 - mse: 4.2017\n",
            "Epoch 81/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2011 - mae: 0.8646 - mse: 4.2011\n",
            "Epoch 82/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1992 - mae: 0.8640 - mse: 4.1992\n",
            "Epoch 83/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2002 - mae: 0.8636 - mse: 4.2002\n",
            "Epoch 84/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1988 - mae: 0.8637 - mse: 4.1988\n",
            "Epoch 85/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1990 - mae: 0.8632 - mse: 4.1990\n",
            "Epoch 86/100\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1999 - mae: 0.8639 - mse: 4.1999\n",
            "Epoch 87/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1997 - mae: 0.8638 - mse: 4.1997\n",
            "Epoch 88/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2009 - mae: 0.8641 - mse: 4.2009\n",
            "Epoch 89/100\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1996 - mae: 0.8633 - mse: 4.1996\n",
            "Epoch 90/100\n",
            "10093/10093 [==============================] - 37s 4ms/step - loss: 4.2005 - mae: 0.8639 - mse: 4.2005\n",
            "Epoch 91/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.2005 - mae: 0.8644 - mse: 4.2005\n",
            "Epoch 92/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1987 - mae: 0.8635 - mse: 4.1987\n",
            "Epoch 93/100\n",
            "10093/10093 [==============================] - 38s 4ms/step - loss: 4.1982 - mae: 0.8633 - mse: 4.1982\n",
            "Epoch 94/100\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1983 - mae: 0.8637 - mse: 4.1983\n",
            "Epoch 95/100\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1988 - mae: 0.8634 - mse: 4.1988\n",
            "Epoch 96/100\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1976 - mae: 0.8634 - mse: 4.1976\n",
            "Epoch 97/100\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1975 - mae: 0.8635 - mse: 4.1975\n",
            "Epoch 98/100\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1973 - mae: 0.8633 - mse: 4.1973\n",
            "Epoch 99/100\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1974 - mae: 0.8635 - mse: 4.1974\n",
            "Epoch 100/100\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1961 - mae: 0.8633 - mse: 4.1961\n",
            "Epoch 1/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1970 - mae: 0.8629 - mse: 4.1970\n",
            "Epoch 2/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1949 - mae: 0.8625 - mse: 4.1949\n",
            "Epoch 3/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1960 - mae: 0.8632 - mse: 4.1960\n",
            "Epoch 4/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1942 - mae: 0.8629 - mse: 4.1942\n",
            "Epoch 5/85\n",
            "10093/10093 [==============================] - 43s 4ms/step - loss: 4.1939 - mae: 0.8628 - mse: 4.1939\n",
            "Epoch 6/85\n",
            "10093/10093 [==============================] - 43s 4ms/step - loss: 4.1943 - mae: 0.8626 - mse: 4.1943\n",
            "Epoch 7/85\n",
            "10093/10093 [==============================] - 44s 4ms/step - loss: 4.1948 - mae: 0.8626 - mse: 4.1948\n",
            "Epoch 8/85\n",
            "10093/10093 [==============================] - 43s 4ms/step - loss: 4.1937 - mae: 0.8622 - mse: 4.1937\n",
            "Epoch 9/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1914 - mae: 0.8620 - mse: 4.1914\n",
            "Epoch 10/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1923 - mae: 0.8620 - mse: 4.1923\n",
            "Epoch 11/85\n",
            "10093/10093 [==============================] - 43s 4ms/step - loss: 4.1919 - mae: 0.8624 - mse: 4.1919\n",
            "Epoch 12/85\n",
            "10093/10093 [==============================] - 48s 5ms/step - loss: 4.1924 - mae: 0.8622 - mse: 4.1924\n",
            "Epoch 13/85\n",
            "10093/10093 [==============================] - 49s 5ms/step - loss: 4.1924 - mae: 0.8617 - mse: 4.1924\n",
            "Epoch 14/85\n",
            "10093/10093 [==============================] - 49s 5ms/step - loss: 4.1913 - mae: 0.8617 - mse: 4.1913\n",
            "Epoch 15/85\n",
            "10093/10093 [==============================] - 44s 4ms/step - loss: 4.1920 - mae: 0.8623 - mse: 4.1920\n",
            "Epoch 16/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1918 - mae: 0.8619 - mse: 4.1918\n",
            "Epoch 17/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1892 - mae: 0.8611 - mse: 4.1892\n",
            "Epoch 18/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1893 - mae: 0.8619 - mse: 4.1893\n",
            "Epoch 19/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1905 - mae: 0.8620 - mse: 4.1905\n",
            "Epoch 20/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1902 - mae: 0.8622 - mse: 4.1902\n",
            "Epoch 21/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1901 - mae: 0.8618 - mse: 4.1901\n",
            "Epoch 22/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1898 - mae: 0.8618 - mse: 4.1898\n",
            "Epoch 23/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1877 - mae: 0.8609 - mse: 4.1877\n",
            "Epoch 24/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1871 - mae: 0.8609 - mse: 4.1871\n",
            "Epoch 25/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1875 - mae: 0.8609 - mse: 4.1875\n",
            "Epoch 26/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1861 - mae: 0.8609 - mse: 4.1861\n",
            "Epoch 27/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1874 - mae: 0.8615 - mse: 4.1874\n",
            "Epoch 28/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1867 - mae: 0.8608 - mse: 4.1867\n",
            "Epoch 29/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1867 - mae: 0.8610 - mse: 4.1867\n",
            "Epoch 30/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1867 - mae: 0.8611 - mse: 4.1867\n",
            "Epoch 31/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1844 - mae: 0.8604 - mse: 4.1844\n",
            "Epoch 32/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1865 - mae: 0.8612 - mse: 4.1865\n",
            "Epoch 33/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1846 - mae: 0.8603 - mse: 4.1846\n",
            "Epoch 34/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1854 - mae: 0.8609 - mse: 4.1854\n",
            "Epoch 35/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1838 - mae: 0.8608 - mse: 4.1838\n",
            "Epoch 36/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1825 - mae: 0.8598 - mse: 4.1825\n",
            "Epoch 37/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1849 - mae: 0.8603 - mse: 4.1849\n",
            "Epoch 38/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1840 - mae: 0.8607 - mse: 4.1840\n",
            "Epoch 39/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1843 - mae: 0.8609 - mse: 4.1843\n",
            "Epoch 40/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1833 - mae: 0.8606 - mse: 4.1833\n",
            "Epoch 41/85\n",
            "10093/10093 [==============================] - 45s 4ms/step - loss: 4.1828 - mae: 0.8602 - mse: 4.1828\n",
            "Epoch 42/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1825 - mae: 0.8607 - mse: 4.1825\n",
            "Epoch 43/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1834 - mae: 0.8600 - mse: 4.1834\n",
            "Epoch 44/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1816 - mae: 0.8600 - mse: 4.1816\n",
            "Epoch 45/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1836 - mae: 0.8606 - mse: 4.1836\n",
            "Epoch 46/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1819 - mae: 0.8603 - mse: 4.1819\n",
            "Epoch 47/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1818 - mae: 0.8605 - mse: 4.1818\n",
            "Epoch 48/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1806 - mae: 0.8596 - mse: 4.1806\n",
            "Epoch 49/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1805 - mae: 0.8596 - mse: 4.1805\n",
            "Epoch 50/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1819 - mae: 0.8606 - mse: 4.1819\n",
            "Epoch 51/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1811 - mae: 0.8599 - mse: 4.1811\n",
            "Epoch 52/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1812 - mae: 0.8600 - mse: 4.1812\n",
            "Epoch 53/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1815 - mae: 0.8599 - mse: 4.1815\n",
            "Epoch 54/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1806 - mae: 0.8601 - mse: 4.1806\n",
            "Epoch 55/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1802 - mae: 0.8596 - mse: 4.1802\n",
            "Epoch 56/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1791 - mae: 0.8592 - mse: 4.1791\n",
            "Epoch 57/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1797 - mae: 0.8595 - mse: 4.1797\n",
            "Epoch 58/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1816 - mae: 0.8602 - mse: 4.1816\n",
            "Epoch 59/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1802 - mae: 0.8598 - mse: 4.1802\n",
            "Epoch 60/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1796 - mae: 0.8592 - mse: 4.1796\n",
            "Epoch 61/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1782 - mae: 0.8587 - mse: 4.1782\n",
            "Epoch 62/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1797 - mae: 0.8588 - mse: 4.1797\n",
            "Epoch 63/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1801 - mae: 0.8592 - mse: 4.1801\n",
            "Epoch 64/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1797 - mae: 0.8597 - mse: 4.1797\n",
            "Epoch 65/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1776 - mae: 0.8588 - mse: 4.1776\n",
            "Epoch 66/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1773 - mae: 0.8588 - mse: 4.1773\n",
            "Epoch 67/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1782 - mae: 0.8585 - mse: 4.1782\n",
            "Epoch 68/85\n",
            "10093/10093 [==============================] - 39s 4ms/step - loss: 4.1779 - mae: 0.8592 - mse: 4.1779\n",
            "Epoch 69/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1778 - mae: 0.8591 - mse: 4.1778\n",
            "Epoch 70/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1784 - mae: 0.8590 - mse: 4.1784\n",
            "Epoch 71/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1772 - mae: 0.8587 - mse: 4.1772\n",
            "Epoch 72/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1765 - mae: 0.8588 - mse: 4.1765\n",
            "Epoch 73/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1790 - mae: 0.8589 - mse: 4.1790\n",
            "Epoch 74/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1774 - mae: 0.8589 - mse: 4.1774\n",
            "Epoch 75/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1782 - mae: 0.8588 - mse: 4.1782\n",
            "Epoch 76/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1766 - mae: 0.8583 - mse: 4.1766\n",
            "Epoch 77/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1777 - mae: 0.8588 - mse: 4.1777\n",
            "Epoch 78/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1772 - mae: 0.8586 - mse: 4.1772\n",
            "Epoch 79/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1780 - mae: 0.8597 - mse: 4.1780\n",
            "Epoch 80/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1771 - mae: 0.8592 - mse: 4.1771\n",
            "Epoch 81/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1756 - mae: 0.8580 - mse: 4.1756\n",
            "Epoch 82/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1782 - mae: 0.8590 - mse: 4.1782\n",
            "Epoch 83/85\n",
            "10093/10093 [==============================] - 40s 4ms/step - loss: 4.1771 - mae: 0.8581 - mse: 4.1771\n",
            "Epoch 84/85\n",
            "10093/10093 [==============================] - 42s 4ms/step - loss: 4.1763 - mae: 0.8581 - mse: 4.1763\n",
            "Epoch 85/85\n",
            "10093/10093 [==============================] - 41s 4ms/step - loss: 4.1772 - mae: 0.8585 - mse: 4.1772\n",
            "16221/16221 [==============================] - 33s 2ms/step - loss: 4.3060 - mae: 0.8696 - mse: 4.3060\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.306046485900879, 0.8695584535598755, 4.306046485900879]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LuirDhHzQNp"
      },
      "source": [
        "#RESULTADO\n",
        "MAE: 0.869\n",
        "\n",
        "MSE: 4.306\n",
        "\n",
        "EPOCH: 85\n",
        "\n",
        "TAXA DE APRENDIZAGEM: 0.007\n",
        "\n",
        "NEURONIOS: 30"
      ]
    }
  ]
}